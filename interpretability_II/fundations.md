# ğŸ¯ GuÃ­a de Preguntas - Fundamentos MÃ³dulo II (Solo Conceptos Nuevos)

## Instrucciones
Estas son las preguntas sobre conceptos **nuevos** que no vimos en MÃ³dulo I. EnfÃ³cate en lo que necesitas para NLP con Transformers.

---

## ğŸ¤– BLOQUE 1: Arquitectura de Transformers (LO NUEVO)

### Conceptos Esenciales

**1.1** Â¿QuÃ© es el mecanismo de **self-attention**? Explica con un ejemplo simple de una oraciÃ³n.

**1.2** Â¿QuÃ© es **multi-head attention**? Â¿Por quÃ© usar 12 "cabezas" en vez de 1?

**1.3** Dibuja un diagrama simplificado: Â¿CÃ³mo fluye el texto desde input hasta predicciÃ³n en DistilBERT?

**1.4** Â¿QuÃ© es el token `[CLS]` y por quÃ© lo usamos para clasificaciÃ³n?

**1.5** Â¿QuÃ© son **positional embeddings**? Â¿Por quÃ© los Transformers los necesitan?

---

### BERT vs DistilBERT

**1.6** Â¿CuÃ¡l es la diferencia principal entre BERT y DistilBERT? (capas, parÃ¡metros, velocidad)

**1.7** Â¿QuÃ© significa "destilar" conocimiento de un modelo grande a uno pequeÃ±o?

**1.8** Para nuestro proyecto, Â¿por quÃ© elegimos DistilBERT en vez de BERT completo?

---

### Fine-tuning (EspecÃ­fico para ClasificaciÃ³n)

**1.9** Â¿QuÃ© significa hacer **fine-tuning** de un modelo pre-entrenado?

**1.10** Â¿QuÃ© capa se agrega encima de DistilBERT para hacer clasificaciÃ³n de sentimientos?

**1.11** Â¿QuÃ© ventaja tiene usar un modelo pre-entrenado vs entrenar desde cero?

---

## ğŸ” BLOQUE 2: SHAP para NLP (LO NUEVO)

### Diferencias con SHAP Tabular

**2.1** En MÃ³dulo I usamos SHAP con XGBoost (datos tabulares). Â¿QuÃ© cambia al aplicarlo a texto?

**2.2** Para un modelo de texto, Â¿las "features" son palabras, tokens o algo mÃ¡s?

**2.3** Â¿CÃ³mo "enmascara" SHAP palabras en una oraciÃ³n para calcular importancia?

**2.4** Â¿QuÃ© estrategia de masking se usa con Transformers? (Â¿tokens en blanco, [MASK], eliminaciÃ³n?)

---

### SHAP con Transformers

**2.5** Â¿Usaremos `TreeExplainer` (como en MÃ³dulo I) o `Explainer` genÃ©rico? Â¿Por quÃ©?

**2.6** Â¿QuÃ© significa un SHAP value de +0.5 para la palabra "excelente" en anÃ¡lisis de sentimientos?

**2.7** Â¿CÃ³mo agregamos SHAP values de mÃºltiples ejemplos para obtener importancia global de palabras?

---

## ğŸ‹ BLOQUE 3: LIME para Texto (LO NUEVO)

### Algoritmo de PerturbaciÃ³n

**3.1** Para texto, Â¿cÃ³mo "perturba" LIME una oraciÃ³n? Da un ejemplo concreto.

Ejemplo: `"This movie is absolutely fantastic"`
Â¿QuÃ© perturbaciones crearÃ­a LIME?

**3.2** Â¿Por quÃ© LIME usa un modelo lineal local si DistilBERT es sÃºper complejo?

**3.3** Â¿CuÃ¡ntas perturbaciones genera LIME tÃ­picamente para una explicaciÃ³n? Â¿MÃ¡s es mejor?

---

### ConfiguraciÃ³n para Transformers

**3.4** Â¿QuÃ© es el parÃ¡metro `num_features` en LIME? Â¿CuÃ¡nto usaremos (5, 10, 20)?

**3.5** Â¿LIME da siempre las mismas explicaciones para el mismo input? Â¿Por quÃ© sÃ­ o no?

**3.6** Â¿QuÃ© diferencia hay entre aplicar LIME a un texto corto (1 lÃ­nea) vs largo (pÃ¡rrafo)?

---

## âš–ï¸ BLOQUE 4: SHAP vs LIME en NLP

### ComparaciÃ³n EspecÃ­fica para Texto

**4.1** Resume en una tabla para tu proyecto:
| Aspecto | SHAP (Transformers) | LIME (Texto) |
|---------|---------------------|--------------|
| Velocidad tÃ­pica | ? segundos | ? segundos |
| Â¿Estable? | SÃ­/No | SÃ­/No |
| Mejor para... | ? | ? |

**4.2** Si SHAP dice "excelente" es importante (+0.5) pero LIME dice "fantastic" (+0.8), Â¿cÃ³mo interpretas eso?

**4.3** Â¿CuÃ¡ndo preferirÃ­as SHAP sobre LIME en este proyecto de sentimientos?

**4.4** Â¿Para quÃ© usarÃ¡s cada uno en tu dashboard final?

---

## ğŸ¯ BLOQUE 5: ValidaciÃ³n de Explicaciones (LO NUEVO)

### MÃ©tricas que ImplementarÃ¡s

**5.1** Â¿QuÃ© es **fidelidad** de una explicaciÃ³n? Describe cÃ³mo la medirÃ¡s en cÃ³digo.

**5.2** PropÃ³n un test simple: Si elimino la palabra mÃ¡s importante segÃºn SHAP, Â¿quÃ© deberÃ­a pasar?

**5.3** Â¿CÃ³mo medirÃ­as si SHAP y LIME "estÃ¡n de acuerdo" en un ejemplo?

**5.4** Â¿QuÃ© experimento harÃ­as para verificar que no estÃ¡n dando explicaciones aleatorias?

---

## ğŸš€ BLOQUE 6: ImplementaciÃ³n PrÃ¡ctica

### Tu Stack TÃ©cnico

**6.1** Â¿QuÃ© librerÃ­a usarÃ¡s para cargar DistilBERT? (nombre exacto)

**6.2** Â¿QuÃ© dataset de HuggingFace usarÃ¡s? Â¿CuÃ¡ntos ejemplos?

**6.3** Lista las 3 clases principales que implementarÃ¡s:
   - `ModelLoader`: Â¿QuÃ© hace?
   - `SHAPAnalyzer`: Â¿QuÃ© hace?
   - `LIMEAnalyzer`: Â¿QuÃ© hace?

---

### Visualizaciones

**6.4** Describe 2 visualizaciones que crearÃ¡s:
   - Para SHAP: ?
   - Para LIME: ?

**6.5** En tu dashboard Streamlit, Â¿quÃ© podrÃ¡ hacer el usuario?

---

## âœ… Checklist de Completitud

- [ ] **BLOQUE 1:** Transformers (11 preguntas) - Arquitectura que no viste en MÃ³dulo I
- [ ] **BLOQUE 2:** SHAP para NLP (7 preguntas) - Diferencias con SHAP tabular
- [ ] **BLOQUE 3:** LIME para Texto (6 preguntas) - MÃ©todo completamente nuevo
- [ ] **BLOQUE 4:** ComparaciÃ³n especÃ­fica (4 preguntas) - Para tu proyecto
- [ ] **BLOQUE 5:** ValidaciÃ³n (4 preguntas) - MÃ©tricas nuevas
- [ ] **BLOQUE 6:** ImplementaciÃ³n (5 preguntas) - Tu cÃ³digo especÃ­fico

**Total: 37 preguntas** (enfocadas en lo nuevo)

---

## ğŸ“š Recursos MÃ­nimos Necesarios

**Para Transformers:**
- Tutorial: "The Illustrated Transformer" (jalammar.github.io)
- Paper: "Attention is All You Need" (solo secciÃ³n 3)
- Docs: HuggingFace DistilBERT model card

**Para SHAP/LIME en NLP:**
- SHAP docs: SecciÃ³n "Text models"
- LIME docs: `LimeTextExplainer` API
- Tutorial: SHAP text examples en GitHub oficial

---

## ğŸ¯ Siguiente Paso

1. Responde estas 37 preguntas (guarda en `docs/01_fundamentos_respuestas.md`)
2. Identifica las 3-5 preguntas mÃ¡s difÃ­ciles
3. Busca recursos especÃ­ficos para esas
4. Â¡Pasa a Semana 2 (ejemplo toy)!

---

## ğŸ’¡ Tip: Estrategia de Estudio

**Prioridad ALTA (responde primero):**
- Bloque 1: Preguntas 1.1, 1.3, 1.4, 1.9
- Bloque 2: Preguntas 2.1, 2.3, 2.5
- Bloque 3: Preguntas 3.1, 3.2
- Bloque 6: Todas

**Prioridad MEDIA:**
- El resto de Bloques 2 y 3
- Bloque 4 completo

**Prioridad BAJA (puedes aprender haciendo):**
- Bloque 5 (aprenderÃ¡s implementando)