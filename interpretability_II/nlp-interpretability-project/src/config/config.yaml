# ============================================================================
# CONFIG.YAML - Configuraciones Centralizadas
# Proyecto: Interpretabilidad en NLP con DistilBERT
# M칩dulo II: SHAP + LIME
# ============================================================================

# ----------------------------------------------------------------------------
# PROYECTO: Informaci칩n general
# ----------------------------------------------------------------------------
project:
  name: "nlp-interpretability-project"
  version: "1.0.0"
  description: "An치lisis de sentimientos con DistilBERT usando SHAP y LIME"
  author: "Estudiante M칩dulo II"
  created_date: "2025-01-15"

# ----------------------------------------------------------------------------
# PATHS: Rutas de archivos y directorios
# ----------------------------------------------------------------------------
paths:
  # Directorio ra칤z del proyecto
  root: "."

  # Datos
  data_dir: "data"
  cache_dir: "data/cache"
  raw_data: "data/raw"
  processed_data: "data/processed"

  # Modelos
  models_dir: "data/models"
  checkpoints_dir: "checkpoints"

  # Resultados
  results_dir: "results"
  plots_dir: "results/plots"
  logs_dir: "results/logs"

  # Notebooks
  notebooks_dir: "notebooks"

  # Aplicaci칩n
  streamlit_cache: ".streamlit/cache"

# ----------------------------------------------------------------------------
# MODEL: Configuraci칩n del modelo DistilBERT
# ----------------------------------------------------------------------------
model:
  # Nombre del modelo en HuggingFace Hub
  name: "distilbert-base-uncased-finetuned-sst-2-english"

  # OPCI칍N A: RoBERTa (Mejor precisi칩n)
  # name: "cardiffnlp/twitter-roberta-base-sentiment-latest"

  # OPCI칍N B: BERT completo (M치s preciso que DistilBERT)
  # name: "textattack/bert-base-uncased-SST-2"

  # OPCI칍N C: Multiling칲e (Si necesitas espa침ol)
  # name: "lxyuan/distilbert-base-multilingual-cased-sentiments-student"

  # Alternativas (comentadas):
  # name: "distilbert-base-uncased"  # Sin fine-tune
  # name: "distilbert-base-uncased-finetuned-sst-2-english" # Fine-tuned en SST-2
  # name: "bert-base-uncased"         # BERT completo (m치s lento)

  # Par치metros del modelo
  max_length: 512 # M치ximo de tokens (l칤mite de DistilBERT)
  truncation: true # Truncar textos largos
  padding: "max_length" # Estrategia de padding
  return_tensors: "pt" # PyTorch tensors

  # Device configuration
  device: "auto" # Opciones: "auto", "cpu", "cuda", "mps"

  # Inferencia
  batch_size: 8 # Batch size para predicciones
  num_workers: 2 # Workers para DataLoader

  # Cache
  cache_model: true # Cachear modelo descargado
  use_fast_tokenizer: true # Usar tokenizer r치pido (Rust)
# ----------------------------------------------------------------------------
# DATASET: Configuraci칩n del dataset IMDb
# ----------------------------------------------------------------------------
dataset:
  # Nombre del dataset en HuggingFace
  name: "imdb"

  # Splits a utilizar
  train_split: "train"
  test_split: "test"

  # Tama침os (null = usar todo el dataset)
  train_size: null # null = 25,000 ejemplos
  test_size: 1000 # Limitar a 1000 para experimentaci칩n r치pida

  # Validaci칩n
  validation_split: 0.1 # 10% del train para validaci칩n

  # Preprocessing
  lowercase: true # Convertir a min칰sculas
  remove_html: true # Eliminar tags HTML
  remove_urls: true # Eliminar URLs
  remove_special_chars: false # Mantener puntuaci칩n

  # Filtros
  min_length: 10 # M칤nimo de palabras por review
  max_length: 512 # M치ximo de palabras (por l칤mite del modelo)

  # Cache
  cache_dataset: true # Cachear dataset descargado

# # ----------------------------------------------------------------------------
# # DATASET: Configuraci칩n del dataset SST2
# # ----------------------------------------------------------------------------
# dataset:
#   # CAMBIO 1: Nombre del dataset
#   name: "sst2"

#   # CAMBIO 2: Splits (SST-2 usa nombres diferentes)
#   train_split: "train" # SST-2 usa "train"
#   test_split: "validation" # SST-2 usa "validation" como test (no tiene "test" p칰blico)

#   # CAMBIO 3: Tama침os (SST-2 es m치s peque침o que IMDb)
#   train_size: null # null = usar todo (67,349 ejemplos)
#   test_size: 1000 # Limitar a 1000 para evaluaci칩n r치pida (de 872 totales, usar치 todos)

#   # CAMBIO 4: Split de validaci칩n
#   validation_split: 0.1 # Puede mantenerse igual

#   # CAMBIO 5: Preprocesamiento (SST-2 ya viene limpio)
#   lowercase: false # SST-2 ya est치 preprocesado
#   remove_html: false # No hay HTML en SST-2
#   remove_urls: false # No hay URLs en SST-2
#   remove_special_chars: false # Mantener puntuaci칩n

#   # CAMBIO 6: Longitudes (SST-2 tiene frases m치s cortas)
#   min_length: 5 # Frases muy cortas en SST-2
#   max_length: 200 # SST-2 tiene frases cortas, no reviews largos

#   # Cache
#   cache_dataset: true # Cachear dataset descargado

# ----------------------------------------------------------------------------
# SHAP: Configuraci칩n de SHAP Explainer
# ----------------------------------------------------------------------------
shap:
  # Tipo de explainer
  explainer_type: "Partition" # Opciones: "Partition", "Kernel", "Sampling"

  # Par치metros de perturbaci칩n
  num_samples: 1000 # N칰mero de perturbaciones (m치s = mejor, m치s lento)
  max_evals: 2000 # M치ximo de evaluaciones del modelo

  # Masking strategy
  masking_strategy: "mask_token" # Opciones: "mask_token", "remove", "zero"
  mask_token: "[MASK]" # Token para reemplazar palabras

  # Agregaci칩n
  aggregation: "mean" # C칩mo agregar SHAP values: "mean", "sum", "max"

  # Visualizaci칩n
  max_display: 20 # M치ximo de tokens a mostrar en plots
  plot_type: "waterfall" # Tipo de gr치fico por defecto

  # Performance
  batch_size: 16 # Batch size para evaluaciones
  use_cache: true # Cachear explicaciones calculadas
  cache_dir: "data/cache/shap"

  # Timeouts
  timeout_seconds: 300 # Timeout por explicaci칩n (5 min)

# ----------------------------------------------------------------------------
# LIME: Configuraci칩n de LIME Explainer
# ----------------------------------------------------------------------------
lime:
  # Par치metros de perturbaci칩n
  num_samples: 5000 # N칰mero de perturbaciones (t칤pico: 1000-10000)
  num_features: 10 # N칰mero de features en la explicaci칩n

  # Estrategia de perturbaci칩n
  perturbation_strategy: "removal" # Opciones: "removal", "replacement"

  # Modelo local
  kernel_width: 25 # Ancho del kernel para pesos de similitud
  distance_metric: "cosine" # M칠trica de distancia: "cosine", "euclidean"

  # Regularizaci칩n
  feature_selection: "auto" # M칠todo de selecci칩n: "auto", "forward_selection", "lasso"
  alpha: 1.0 # Par치metro de regularizaci칩n

  # Tokenizaci칩n
  split_expression: r'\W+' # Regex para dividir tokens
  bow: true # Bag-of-words representation

  # Reproducibilidad
  random_state: 42 # Seed para reproducibilidad

  # Performance
  use_cache: true # Cachear explicaciones
  cache_dir: "data/cache/lime"

  # Timeouts
  timeout_seconds: 180 # Timeout por explicaci칩n (3 min)

# ----------------------------------------------------------------------------
# EVALUATION: M칠tricas de evaluaci칩n
# ----------------------------------------------------------------------------
evaluation:
  # M칠tricas del modelo base
  model_metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_score"
    - "confusion_matrix"

  # M칠tricas de interpretabilidad
  interpretability_metrics:
    - "fidelity" # 쮼xplicaci칩n refleja el modelo?
    - "stability" # 쮺onsistencia entre ejecuciones?
    - "consistency" # 쯉HAP y LIME coinciden?

  # Par치metros de validaci칩n
  fidelity:
    top_k_features: 5 # Top-K features a remover
    perturbation_type: "removal"

  stability:
    num_runs: 10 # Repeticiones para medir estabilidad
    similarity_threshold: 0.7 # Umbral de similitud aceptable

  consistency:
    correlation_method: "spearman" # M칠todo de correlaci칩n
    min_correlation: 0.5 # Correlaci칩n m칤nima aceptable

# ----------------------------------------------------------------------------
# VISUALIZATION: Configuraciones de gr치ficos
# ----------------------------------------------------------------------------
visualization:
  # Configuraci칩n general
  style: "seaborn-v0_8-darkgrid" # Estilo de matplotlib
  context: "notebook" # Contexto de seaborn: "paper", "notebook", "talk", "poster"
  palette: "viridis" # Paleta de colores

  # Tama침os
  figsize:
    default: [10, 6] # Ancho x Alto en pulgadas
    wide: [14, 6]
    square: [8, 8]
    dashboard: [12, 8]

  # DPI y calidad
  dpi: 100 # Resoluci칩n de im치genes
  save_format: "png" # Formato: "png", "pdf", "svg"

  # Fuentes
  font_family: "sans-serif"
  font_size: 12
  title_size: 14
  label_size: 11

  # Colores espec칤ficos
  colors:
    positive: "#4CAF50" # Verde para sentimiento positivo
    negative: "#F44336" # Rojo para sentimiento negativo
    neutral: "#9E9E9E" # Gris para neutro
    shap: "#1E88E5" # Azul para SHAP
    lime: "#FFA726" # Naranja para LIME

  # Plots espec칤ficos
  heatmap:
    cmap: "RdYlGn" # Colormap para importancia de tokens
    vmin: -1.0
    vmax: 1.0
    center: 0.0

  waterfall:
    max_display: 20 # M치ximo de features
    show_data: true

  bar_plot:
    max_features: 15
    horizontal: true

# ----------------------------------------------------------------------------
# DASHBOARD: Configuraci칩n de Streamlit
# ----------------------------------------------------------------------------
dashboard:
  # Configuraci칩n general
  title: "游댌 Explicador de Sentimientos - DistilBERT"
  page_icon: "游뱄"
  layout: "wide" # "centered" o "wide"
  initial_sidebar_state: "expanded"

  # L칤mites
  max_input_length: 500 # M치ximo de caracteres en input
  examples_to_show: 5 # Ejemplos predefinidos

  # Features habilitadas
  enable_shap: true
  enable_lime: true
  enable_comparison: true # Comparaci칩n lado a lado
  enable_batch: false # An치lisis de m칰ltiples textos (futuro)

  # Performance
  cache_predictions: true # Cachear predicciones
  show_progress: true # Mostrar barras de progreso

  # Ejemplos predefinidos
  examples:
    - "This movie was absolutely fantastic! I loved every minute of it."
    - "Terrible waste of time. I want my money back."
    - "It was okay, nothing special but not bad either."
    - "The acting was superb, but the plot was confusing and slow."
    - "I've never seen anything more boring in my entire life."

# ----------------------------------------------------------------------------
# LOGGING: Configuraci칩n de logs
# ----------------------------------------------------------------------------
logging:
  # Nivel de logging
  level: "INFO" # DEBUG, INFO, WARNING, ERROR, CRITICAL

  # Formato
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  date_format: "%Y-%m-%d %H:%M:%S"

  # Archivos
  log_to_file: true
  log_file: "results/logs/app.log"
  max_bytes: 10485760 # 10MB
  backup_count: 5 # Mantener 5 archivos de backup

  # Console output
  log_to_console: true
  console_level: "INFO"

# ----------------------------------------------------------------------------
# EXPERIMENT: Configuraci칩n de experimentos
# ----------------------------------------------------------------------------
experiment:
  # Identificaci칩n
  name: "baseline_distilbert"
  description: "Evaluaci칩n base de DistilBERT con SHAP y LIME"

  # Reproducibilidad
  random_seed: 42
  deterministic: true

  # Casos de estudio
  num_case_studies: 10 # N칰mero de casos a analizar en detalle

  # Selecci칩n de casos
  case_selection:
    - "high_confidence_correct" # Predicciones correctas con alta confianza
    - "high_confidence_incorrect" # Predicciones incorrecas con alta confianza
    - "low_confidence" # Predicciones con baja confianza
    - "disagreement" # SHAP y LIME no coinciden
    - "ambiguous" # Textos ambiguos o sarc치sticos

# ----------------------------------------------------------------------------
# PERFORMANCE: Optimizaciones
# ----------------------------------------------------------------------------
performance:
  # Multiprocessing
  use_multiprocessing: false # Usar m칰ltiples procesos (cuidado con CUDA)
  num_processes: 4 # N칰mero de procesos paralelos

  # Memory management
  clear_cache_frequency: 100 # Limpiar cache cada N iteraciones
  max_cache_size_mb: 2048 # Tama침o m치ximo de cache (2GB)

  # GPU
  fp16: false # Usar precisi칩n mixta (m치s r치pido, menos preciso)
  gpu_memory_fraction: 0.8 # Fracci칩n de GPU a usar

# ----------------------------------------------------------------------------
# DESARROLLO: Flags de desarrollo
# ----------------------------------------------------------------------------
development:
  debug_mode: false # Modo debug (m치s verbose)
  profile_code: false # Profiling de performance
  save_intermediate: true # Guardar resultados intermedios

  # Testing
  test_mode: false # Usar subset peque침o para testing r치pido
  test_sample_size: 10 # Tama침o de muestra en test mode

  # Warnings
  ignore_warnings: false # Suprimir warnings de librer칤as

# ============================================================================
# NOTAS DE USO
# ============================================================================
#
# 1. CARGAR CONFIGURACI칍N EN PYTHON:
#    ```python
#    import yaml
#    with open('src/config/config.yaml', 'r') as f:
#        config = yaml.safe_load(f)
#
#    # Acceder a valores
#    model_name = config['model']['name']
#    shap_samples = config['shap']['num_samples']
#    ```
#
# 2. VARIABLES DE ENTORNO:
#    Puedes usar variables de entorno para valores sensibles:
#    ${HUGGINGFACE_TOKEN}
#
# 3. PROFILES:
#    Crea configs espec칤ficos: config_dev.yaml, config_prod.yaml
#
# 4. VALIDACI칍N:
#    Siempre valida que las rutas existan antes de usar
#
# ============================================================================
