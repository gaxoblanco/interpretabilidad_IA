# ğŸ§  Interpretabilidad en Machine Learning

Proyecto educativo progresivo para dominar tÃ©cnicas de interpretabilidad en ML, siguiendo el roadmap estructurado en [`roadmap.md`](roadmap.md).

---

## ğŸ“‚ MÃ³dulos

### âœ… `interpretability_I/` - German Credit Risk (XGBoost + SHAP)
**Estado:** Completado | **Tipo:** Datos Tabulares

AnÃ¡lisis de riesgo crediticio con modelos de clasificaciÃ³n tabular.

- **Modelo:** XGBoost (78% accuracy, 0.809 ROC-AUC)
- **Dataset:** German Credit Data (1000 clientes, 20 features)
- **TÃ©cnicas:** SHAP values, Waterfall plots, Counterfactual explanations
- **Dashboard:** Streamlit interactivo con predicciones en tiempo real

**Aprendizajes clave:**
- SHAP > Feature Importance para interpretabilidad real
- Counterfactuals: explicabilidad accionable ("quÃ© cambiar para aprobar")
- Trade-offs: Recall vs Precision en clasificaciÃ³n desbalanceada
- ComunicaciÃ³n: Traducir valores SHAP a lenguaje de negocio

ğŸ“ **Contenido:**
```
interpretability_I/
â”œâ”€â”€ notebooks/           # 4 notebooks: EDA, Modelado, SHAP, Counterfactuals
â”œâ”€â”€ app.py              # Dashboard Streamlit interactivo
â”œâ”€â”€ models/             # Modelos y encoders guardados
â”œâ”€â”€ data/               # Dataset procesado
â”œâ”€â”€ LEARNINGS.md        # Insights y decisiones documentadas
â””â”€â”€ README.md           # DocumentaciÃ³n especÃ­fica del mÃ³dulo
```

---

### ğŸ”œ `interpretability_II/` - Text Classification (DistilBERT + SHAP + LIME)
**Estado:** PrÃ³ximamente | **Tipo:** NLP

Interpretabilidad en modelos de clasificaciÃ³n de texto con Transformers.

**Roadmap detallado:** Ver [`roadmap.md`](roadmap.md) - Proyecto 1

- **Modelo:** DistilBERT fine-tuned para anÃ¡lisis de sentimientos
- **Dataset:** IMDb Reviews (50k reviews balanceados)
- **TÃ©cnicas:** SHAP para texto, LIME, Attention visualization
- **Fases:**
  - **Parte I:** Fundamentos teÃ³ricos (Transformers, SHAP, LIME)
  - **Parte II:** ImplementaciÃ³n (ModelLoader, SHAPAnalyzer, LIMEAnalyzer)
  - **Parte III:** AnÃ¡lisis avanzado (ValidaciÃ³n, casos de estudio)

**DuraciÃ³n estimada:** 7-8 semanas

---

### ğŸ”® `interpretability_III/` - Neuron Activation Analysis
**Estado:** Planificado | **Tipo:** AnÃ¡lisis Interno de Modelos

Interpretabilidad mediante activaciÃ³n de neuronas (Proyecto 2 segÃºn roadmap).

- **Objetivo:** Entender quÃ© representan neuronas individuales en redes profundas
- **TÃ©cnicas:** Feature visualization, Activation maximization, Neuron probing
- **Modelos:** Por definir (CNN o Transformer segÃºn hallazgos del Proyecto 1)

---

### ğŸ”® `interpretability_IV/` - Computer Vision (CNN + GradCAM)
**Estado:** Planificado | **Tipo:** Computer Vision

Interpretabilidad en clasificaciÃ³n de imÃ¡genes.

- **Modelo:** ResNet / EfficientNet
- **Dataset:** Por definir
- **TÃ©cnicas:** GradCAM, Integrated Gradients, Saliency Maps
- **Objetivo:** Visualizar quÃ© regiones de imÃ¡genes activan el modelo

---

## ğŸ—ºï¸ Roadmap General

| MÃ³dulo | Enfoque | Estado | DuraciÃ³n |
|--------|---------|--------|----------|
| **I** | XGBoost + SHAP (Tabular) | âœ… Completado | 3 semanas |
| **II** | DistilBERT + LIME (NLP) | ğŸ”„ Siguiente | 7-8 semanas |
| **III** | Neuron Activation Analysis | ğŸ“‹ Planificado | Por definir |
| **IV** | CNN + GradCAM (Vision) | ğŸ“‹ Planificado | Por definir |

ğŸ“˜ **Roadmap completo:** [`roadmap.md`](roadmap.md) | ğŸ“Š **Notas de estudio:** [`roadmap_study.md`](roadmap_study.md)

---

## ğŸ› ï¸ Stack TecnolÃ³gico

| CategorÃ­a | MÃ³dulo I | MÃ³dulo II (Planeado) | MÃ³dulo III-IV (Planeado) |
|-----------|----------|----------------------|--------------------------|
| **ML Frameworks** | XGBoost, Scikit-learn | Transformers, PyTorch | PyTorch, TensorFlow |
| **Interpretabilidad** | SHAP | SHAP, LIME | Captum, GradCAM |
| **VisualizaciÃ³n** | Matplotlib, Plotly, Streamlit | Plotly, Streamlit | Plotly, PIL |
| **Data** | Pandas, NumPy | Datasets (HF), Pandas | PIL, OpenCV |

---

## ğŸš€ Inicio RÃ¡pido

```bash
# Clonar repositorio
git clone <repo-url>

# Navegar a mÃ³dulo deseado
cd interpretability_I

# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar dashboard (ejemplo mÃ³dulo I)
streamlit run app.py
```

---

## ğŸ“ˆ Progreso

- [x] **MÃ³dulo I:** German Credit + SHAP + Counterfactuals + Dashboard
- [ ] **MÃ³dulo II:** DistilBERT + SHAP + LIME (segÃºn roadmap.md)
  - [ ] Parte I: Fundamentos teÃ³ricos (3 capÃ­tulos)
  - [ ] Parte II: ImplementaciÃ³n prÃ¡ctica (5 capÃ­tulos)
  - [ ] Parte III: AnÃ¡lisis avanzado (3 capÃ­tulos)
- [ ] **MÃ³dulo III:** Neuron Activation Analysis
- [ ] **MÃ³dulo IV:** CNN + GradCAM

---

## ğŸ“š Recursos

- ğŸ“˜ **Roadmap completo:** [`roadmap.md`](roadmap.md) - GuÃ­a detallada por capÃ­tulos y semanas
- ğŸ“Š **Study notes:** [`roadmap_study.md`](roadmap_study.md) - Notas de estudio y referencias
- ğŸ“ **Learnings por mÃ³dulo:** Ver `LEARNINGS.md` en cada carpeta del mÃ³dulo

---

**Ãšltima actualizaciÃ³n:** MÃ³dulo I completado - Octubre 2025