# üìö FUNCIONES IMPLEMENTADAS EN `src/`

Este documento detalla todas las funciones y clases implementadas en el m√≥dulo III del proyecto de interpretabilidad.

---

## üìÅ Estructura de Archivos

```
interpretability_III/src/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ model_loader.py
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ image_loader.py
‚îÇ   ‚îî‚îÄ‚îÄ hooks.py
‚îî‚îÄ‚îÄ (otros m√≥dulos pendientes)
```

---

## üß† `src/models/model_loader.py`

### **Clase Principal: `ModelLoader`**

Carga y analiza modelos pre-entrenados de torchvision.

#### **Constructor:**
```python
ModelLoader(
    model_name: str = 'resnet18',
    pretrained: bool = True,
    num_classes: int = 1000,
    device: Optional[str] = None
)
```
- **Modelos soportados:** resnet18, resnet34, resnet50, resnet101, resnet152, vgg16, vgg19, alexnet, densenet121, mobilenet_v2

#### **M√©todos Principales:**

##### `load_model() -> nn.Module`
- Carga el modelo con o sin pesos pre-entrenados
- Mueve el modelo al device (GPU/CPU)
- Configura en modo evaluaci√≥n por defecto
- **Retorna:** Modelo cargado

##### `get_architecture_info() -> Dict`
- **Retorna diccionario con:**
  - `total_params`: Total de par√°metros
  - `trainable_params`: Par√°metros entrenables
  - `frozen_params`: Par√°metros congelados
  - `model_size_mb`: Tama√±o del modelo en MB
  - `num_layers`: N√∫mero de capas
  - `params_by_type`: Distribuci√≥n de par√°metros por tipo de capa

##### `get_layers_info() -> List[Dict]`
- **Retorna lista de diccionarios con info de cada capa:**
  - `name`: Nombre de la capa
  - `type`: Tipo de capa (Conv2d, Linear, etc.)
  - `params`: N√∫mero de par√°metros
  - `trainable`: Si los par√°metros son entrenables
  - `output_shape`: Shape de salida (si est√° disponible)

##### `get_residual_blocks_info() -> List[Dict]`
- **Solo para ResNet**
- **Retorna lista con info de cada bloque residual:**
  - `name`: Nombre del bloque (e.g., 'layer1.0')
  - `num_layers`: N√∫mero de capas en el bloque
  - `params`: N√∫mero de par√°metros
  - `in_channels`: Canales de entrada
  - `out_channels`: Canales de salida
  - `stride`: Stride del bloque
  - `has_downsample`: Si tiene capa de downsampling

##### `get_layer_by_name(layer_name: str) -> Optional[nn.Module]`
- Obtiene una capa espec√≠fica por su nombre
- **Ejemplo:** `get_layer_by_name('layer1.0.conv1')`

##### `freeze_layers(layer_names: Optional[List[str]] = None)`
- Congela capas espec√≠ficas para no entrenarlas
- Si `layer_names=None`, congela todas las capas

##### `unfreeze_layers(layer_names: Optional[List[str]] = None)`
- Descongela capas espec√≠ficas para entrenarlas
- Si `layer_names=None`, descongela todas las capas

##### `set_eval_mode()`
- Configura el modelo en modo evaluaci√≥n (desactiva dropout, batch norm)

##### `set_train_mode()`
- Configura el modelo en modo entrenamiento

##### `get_model_summary() -> str`
- Genera un resumen legible del modelo con todas las estad√≠sticas

#### **Funciones Auxiliares:**

##### `list_available_models() -> List[str]`
- Lista todos los modelos disponibles para cargar

##### `get_model_info(model_name: str) -> Dict`
- Informaci√≥n b√°sica de un modelo sin cargarlo

---

## üñºÔ∏è `src/utils/image_loader.py`

### **Clase Principal: `ImageLoader`**

Carga y procesa datasets de im√°genes (CIFAR-10, CIFAR-100).

#### **Constructor:**
```python
ImageLoader(
    dataset_name: str = 'cifar10',
    batch_size: int = 32,
    num_workers: int = 2,
    data_dir: Optional[str] = None,
    download: bool = True,
    shuffle_train: bool = True,
    pin_memory: bool = True
)
```
- **Datasets soportados:** cifar10, cifar100

#### **Constantes de Clase:**
```python
IMAGENET_MEAN = [0.485, 0.456, 0.406]  # Normalizaci√≥n ImageNet
IMAGENET_STD = [0.229, 0.224, 0.225]
CIFAR10_CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                   'dog', 'frog', 'horse', 'ship', 'truck']
```

#### **M√©todos Principales:**

##### `load_datasets()`
- Carga los datasets de entrenamiento y prueba
- Aplica transformaciones apropiadas
- Descarga autom√°ticamente si es necesario

##### `get_dataloaders() -> Tuple[DataLoader, DataLoader]`
- Crea y retorna dataloaders de entrenamiento y prueba
- **Retorna:** (train_loader, test_loader)

##### `get_dataset_info() -> Dict`
- **Retorna diccionario con:**
  - `name`: Nombre del dataset
  - `num_classes`: N√∫mero de clases
  - `image_size`: Tama√±o de las im√°genes
  - `train_samples`: N√∫mero de muestras de entrenamiento
  - `test_samples`: N√∫mero de muestras de prueba
  - `classes`: Lista de nombres de clases
  - `normalization_mean`: Media de normalizaci√≥n
  - `normalization_std`: Desviaci√≥n est√°ndar de normalizaci√≥n

##### `denormalize_image(tensor: torch.Tensor) -> np.ndarray`
- Denormaliza una imagen tensor para visualizaci√≥n
- **Input:** Tensor [C, H, W] o [B, C, H, W]
- **Output:** Array numpy [H, W, C] con valores en [0, 1]

##### `normalize_image(img: np.ndarray) -> torch.Tensor`
- Normaliza una imagen numpy para input al modelo
- **Input:** Array [H, W, C] con valores en [0, 255] o [0, 1]
- **Output:** Tensor normalizado [C, H, W]

##### `get_class_distribution(split: str = 'train') -> Dict[str, int]`
- Calcula la distribuci√≥n de clases en el dataset
- **Retorna:** {nombre_clase: n√∫mero_de_muestras}

##### `get_sample_images(num_images: int = 16, split: str = 'test', random: bool = True) -> Tuple[torch.Tensor, torch.Tensor]`
- Obtiene un conjunto de im√°genes de muestra
- **Retorna:** (images, labels) como tensors

##### `load_custom_image(image_path: str, resize: Optional[Tuple[int, int]] = None) -> torch.Tensor`
- Carga y procesa una imagen personalizada
- **Retorna:** Tensor [1, C, H, W] listo para el modelo

##### `get_statistics() -> Dict`
- Calcula estad√≠sticas del dataset (media, std por canal)
- **Nota:** Puede ser lento para datasets grandes

#### **Funciones Auxiliares:**

##### `visualize_augmentations(dataset: Dataset, num_examples: int = 4)`
- Visualiza ejemplos de data augmentation

##### `calculate_dataset_mean_std(dataloader: DataLoader) -> Tuple[List[float], List[float]]`
- Calcula la media y desviaci√≥n est√°ndar de un dataset

---

## ü™ù `src/utils/hooks.py`

### **Clase Principal: `ActivationHook`**

Sistema de hooks para capturar activaciones de capas intermedias.

#### **Constructor:**
```python
ActivationHook(
    model: nn.Module,
    target_layers: Optional[List[str]] = None
)
```
- Si `target_layers=None`, registra hooks en todas las capas Conv2d

#### **Atributos:**
```python
self.model          # Modelo de PyTorch
self.target_layers  # Lista de nombres de capas objetivo
self.activations    # OrderedDict con activaciones capturadas
self.gradients      # OrderedDict con gradientes capturados
self.hooks          # Lista de handles de hooks registrados
```

#### **M√©todos Principales:**

##### `register_hooks(capture_gradients: bool = False)`
- Registra hooks en las capas objetivo
- Si `capture_gradients=True`, tambi√©n captura gradientes (backward hooks)

##### `remove_hooks()`
- Remueve todos los hooks registrados
- Libera recursos

##### `get_activations() -> Dict[str, torch.Tensor]`
- Obtiene las activaciones capturadas
- **Retorna:** {layer_name: activation_tensor}

##### `get_gradients() -> Dict[str, torch.Tensor]`
- Obtiene los gradientes capturados
- Requiere `capture_gradients=True` en `register_hooks()`
- Requiere haber ejecutado backward pass

##### `clear_activations()`
- Limpia las activaciones almacenadas
- √ötil para liberar memoria entre forward passes

##### `get_activation_shapes() -> Dict[str, Tuple]`
- **Retorna:** {layer_name: shape_tuple}

##### `get_activation_statistics() -> Dict[str, Dict]`
- Calcula estad√≠sticas completas de las activaciones
- **Retorna diccionario por capa con:**
  - `mean`: Media de la activaci√≥n
  - `std`: Desviaci√≥n est√°ndar
  - `min`: Valor m√≠nimo
  - `max`: Valor m√°ximo
  - `sparsity`: Proporci√≥n de valores == 0
  - `active_neurons`: N√∫mero de neuronas activas
  - `total_neurons`: Total de neuronas
  - `shape`: Shape del tensor

##### `get_layer_names() -> List[str]`
- Obtiene la lista de nombres de capas objetivo

##### `has_activations() -> bool`
- Verifica si hay activaciones capturadas

##### `get_activation_for_layer(layer_name: str) -> Optional[torch.Tensor]`
- Obtiene la activaci√≥n de una capa espec√≠fica

##### `save_activations(filepath: str)`
- Guarda las activaciones en un archivo .pth

##### `load_activations(filepath: str)`
- Carga activaciones desde un archivo .pth

#### **Funciones Auxiliares:**

##### `get_all_layer_names(model: nn.Module) -> List[str]`
- Obtiene todos los nombres de capas del modelo

##### `get_layer_types(model: nn.Module) -> Dict[str, List[str]]`
- Agrupa las capas del modelo por tipo
- **Retorna:** {tipo_de_capa: [nombres_de_capas]}

##### `compare_activations(activations1: Dict, activations2: Dict) -> Dict[str, Dict]`
- Compara dos conjuntos de activaciones
- **Retorna m√©tricas por capa:**
  - `mean_abs_diff`: Diferencia absoluta media
  - `max_abs_diff`: Diferencia absoluta m√°xima
  - `cosine_similarity`: Similitud coseno
  - `correlation`: Correlaci√≥n

##### `find_dead_neurons(activations: Dict, threshold: float = 0.0) -> Dict[str, List[int]]`
- Identifica neuronas "muertas" (que nunca se activan)
- **Retorna:** {layer_name: [indices_de_neuronas_muertas]}

##### `analyze_sparsity(activations: Dict) -> Dict[str, float]`
- Analiza la sparsity de las activaciones
- **Retorna:** {layer_name: sparsity_percentage}

---

## üìù Ejemplos de Uso

### **Cargar Modelo:**
```python
from src.models.model_loader import ModelLoader

loader = ModelLoader('resnet18', pretrained=True)
model = loader.load_model()
arch_info = loader.get_architecture_info()
```

### **Cargar Dataset:**
```python
from src.utils.image_loader import ImageLoader

img_loader = ImageLoader('cifar10', batch_size=32)
train_loader, test_loader = img_loader.get_dataloaders()
dataset_info = img_loader.get_dataset_info()
```

### **Capturar Activaciones:**
```python
from src.utils.hooks import ActivationHook

target_layers = ['conv1', 'layer1.0.conv1', 'layer4.0.conv1']
hook = ActivationHook(model, target_layers)
hook.register_hooks()

# Forward pass
output = model(input_tensor)

# Obtener activaciones
activations = hook.get_activations()
stats = hook.get_activation_statistics()

# Limpiar
hook.clear_activations()
hook.remove_hooks()
```

---

## ‚úÖ Estado de Implementaci√≥n

| M√≥dulo | Archivo | Estado | Funciones |
|--------|---------|--------|-----------|
| **models** | model_loader.py | ‚úÖ Completo | 13 m√©todos |
| **utils** | image_loader.py | ‚úÖ Completo | 12 m√©todos |
| **utils** | hooks.py | ‚úÖ Completo | 16 m√©todos |
| **interpretability** | (pendiente) | ‚ùå Por implementar | - |
| **visualization** | (pendiente) | ‚ùå Por implementar | - |

---

## üéØ Pr√≥ximas Implementaciones (Notebook 02+)

### **`src/interpretability/`** (Pendiente)
- `activation_extractor.py`: Extraer activaciones de todas las capas
- `feature_visualizer.py`: Generar feature visualizations
- `neuron_probe.py`: Probing classifiers
- `activation_analyzer.py`: An√°lisis estad√≠stico avanzado

### **`src/visualization/`** (Pendiente)
- `heatmap_viz.py`: Mapas de calor de activaciones
- `filter_viz.py`: Visualizaci√≥n de filtros
- `layer_viz.py`: Visualizaci√≥n por capas

---

## üìå Notas Importantes

1. **Todas las funciones est√°n documentadas** con docstrings completos
2. **Logging integrado** para debugging
3. **Manejo de errores** con mensajes descriptivos
4. **Type hints** en todos los m√©todos
5. **Ejemplos de uso** al final de cada archivo

---

**√öltima actualizaci√≥n:** 2025-01-15
**Versi√≥n del proyecto:** M√≥dulo III - Notebook 01 Completado