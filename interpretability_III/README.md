ðŸ“‹ Planificado - Por definir duraciÃ³n


**InformaciÃ³n actual:**
- **Objetivo:** Entender quÃ© representan neuronas individuales en redes profundas
- **TÃ©cnicas:** Feature visualization, Activation maximization, Neuron probing
- **Modelos:** Por definir (CNN o Transformer segÃºn hallazgos del Proyecto 1)
- **Stack TecnolÃ³gico:** PyTorch/TensorFlow, Captum, Plotly, PIL

---

## ðŸŽ¯ **PROPUESTA DETALLADA PARA EL MÃ“DULO III**

### **1. Objetivo Principal**

> **"Â¿QuÃ© estÃ¡n aprendiendo las neuronas individuales en mi modelo de Deep Learning, y cÃ³mo puedo visualizarlo?"**

Este mÃ³dulo se enfoca en **interpretabilidad a nivel de arquitectura interna**, complementando los mÃ³dulos anteriores:
- **MÃ³dulo I:** Interpretabilidad de features (datos tabulares)
- **MÃ³dulo II:** Interpretabilidad de tokens/palabras (NLP)
- **MÃ³dulo III:** Interpretabilidad de neuronas (arquitectura interna)

---

### **2. TÃ©cnicas a Implementar**

#### **A) Feature Visualization (VisualizaciÃ³n de Features)**
- **QuÃ© es:** Generar imÃ¡genes sintÃ©ticas que maximalmente activan una neurona especÃ­fica
- **Herramienta:** Lucid (TensorFlow) o pytorch-cnn-visualizations
- **Output:** "Esta neurona detecta ojos", "Esta neurona detecta texturas"

#### **B) Activation Maximization (MaximizaciÃ³n de ActivaciÃ³n)**
- **QuÃ© es:** OptimizaciÃ³n para encontrar el input que maximiza la activaciÃ³n
- **Herramienta:** Captum (PyTorch)
- **Output:** Patrones abstractos que la red "busca"

#### **C) Neuron Probing (Sondeo de Neuronas)**
- **QuÃ© es:** Entrenar clasificadores lineales sobre activaciones para ver quÃ© informaciÃ³n codifican
- **TÃ©cnica:** Probing classifiers
- **Output:** "La capa 3 codifica formas, la capa 5 codifica objetos"

#### **D) Activation Patterns (Patrones de ActivaciÃ³n)**
- **QuÃ© es:** Visualizar quÃ© partes de la imagen activan cada neurona
- **Herramienta:** Activation maps, heatmaps
- **Output:** Mapas de calor de activaciones por capa

---

### **3. Modelo y Dataset Propuestos**

#### **Modelo:**
**ResNet-18 o ResNet-50 pre-entrenado en ImageNet**

**Razones:**
- Arquitectura bien estudiada y documentada
- Pre-entrenado (no requiere training costoso)
- Suficientemente complejo para ser interesante
- Capas residuales facilitan anÃ¡lisis de flujo de informaciÃ³n

#### **Dataset:**
**ImageNet subset o CIFAR-10**

**OpciÃ³n 1 - ImageNet (100 clases):**
- MÃ¡s realista y rico
- Clases interpretables (perros, gatos, vehÃ­culos)
- Puede ser costoso computacionalmente

**OpciÃ³n 2 - CIFAR-10:**
- 10 clases simples (aviones, coches, pÃ¡jaros, gatos, etc.)
- MÃ¡s rÃ¡pido para experimentar
- Suficiente para aprender las tÃ©cnicas

**RecomendaciÃ³n:** Empezar con CIFAR-10 para prototipado rÃ¡pido, luego escalar a ImageNet subset si es necesario

---

## **4. Estructura del Proyecto**

interpretability_III/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_model_loading.ipynb           # Cargar ResNet pre-entrenado
â”‚   â”œâ”€â”€ 02_activation_analysis.ipynb      # Analizar activaciones por capa
â”‚   â”œâ”€â”€ 03_feature_visualization.ipynb    # Generar imÃ¡genes que activan neuronas
â”‚   â”œâ”€â”€ 04_neuron_probing.ipynb          # Clasificadores de sondeo
â”‚   â””â”€â”€ 05_case_studies.ipynb            # Casos de estudio interesantes
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ model_loader.py              # Cargar ResNet con hooks
â”‚   â”‚
â”‚   â”œâ”€â”€ interpretability/
â”‚   â”‚   â”œâ”€â”€ activation_extractor.py      # Extraer activaciones de capas
â”‚   â”‚   â”œâ”€â”€ feature_visualizer.py        # Generar feature visualizations
â”‚   â”‚   â”œâ”€â”€ neuron_probe.py              # Probing classifiers
â”‚   â”‚   â””â”€â”€ activation_analyzer.py       # AnÃ¡lisis estadÃ­stico de activaciones
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â”œâ”€â”€ heatmap_viz.py               # Mapas de calor de activaciones
â”‚   â”‚   â”œâ”€â”€ filter_viz.py                # VisualizaciÃ³n de filtros
â”‚   â”‚   â””â”€â”€ layer_viz.py                 # VisualizaciÃ³n por capas
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ image_loader.py              # Cargar y procesar imÃ¡genes
â”‚       â””â”€â”€ hooks.py                     # PyTorch hooks para capas
â”‚
â”œâ”€â”€ app.py                               # Dashboard Streamlit interactivo
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LEARNINGS.md
â””â”€â”€ README.md

---
## Plan de Trabajo 
Step 1: Setup y Fundamentos

Investigar teorÃ­a de feature visualization
Configurar entorno con PyTorch + Captum
Cargar ResNet pre-entrenado
Implementar hooks para extraer activaciones
Entregable: Notebook de carga del modelo + documentaciÃ³n teÃ³rica

Step 2: ExtracciÃ³n de Activaciones

Implementar ActivationExtractor class
Extraer activaciones de todas las capas para un batch de imÃ¡genes
Analizar estadÃ­sticas de activaciones (media, varianza, sparsity)
Visualizar distribuciones de activaciones
Entregable: Sistema de extracciÃ³n funcionando + anÃ¡lisis exploratorio

Step 3: Feature Visualization

Implementar tÃ©cnica de activation maximization
Generar imÃ¡genes sintÃ©ticas para neuronas individuales
Visualizar quÃ© detectan los filtros de conv1, conv2, etc.
Identificar neuronas de "alto nivel" vs "bajo nivel"
Entregable: GalerÃ­a de feature visualizations por capa

Step 4: Neuron Probing

Entrenar clasificadores lineales sobre activaciones
Probar quÃ© informaciÃ³n codifica cada capa (colores, formas, objetos)
AnÃ¡lisis de "emergencia" de conceptos en capas profundas
Entregable: AnÃ¡lisis de quÃ© codifica cada capa

Step 5: Activation Patterns y Heatmaps

Crear mapas de calor de activaciones por imagen
Visualizar quÃ© regiones activan cada neurona
Comparar patrones entre clases (gatos vs perros)
Entregable: Sistema de visualizaciÃ³n de activation maps

Step 6: Dashboard y Casos de Estudio

Crear dashboard interactivo con Streamlit
Permitir al usuario subir imagen y explorar activaciones
Documentar 5-10 casos de estudio interesantes
Entregable: Dashboard funcionando + casos documentados

Step 7: ConsolidaciÃ³n y PreparaciÃ³n MÃ³dulo IV

Documentar limitaciones encontradas
Crear LEARNINGS.md con insights clave
DiseÃ±ar transiciÃ³n a MÃ³dulo IV (GradCAM)
Entregable: Reporte final + roadmap MÃ³dulo IV


## Criterios de Ã‰xito

 Sistema funcionando para extraer y visualizar activaciones de cualquier capa
 GalerÃ­a de al menos 20 feature visualizations de neuronas interesantes
 AnÃ¡lisis de probing que muestre quÃ© codifica cada capa
 Dashboard interactivo donde se pueda subir una imagen y explorar
 IdentificaciÃ³n de al menos 3 insights sorprendentes sobre la red
 DocumentaciÃ³n completa de limitaciones y aprendizajes
 Base sÃ³lida para transicionar a MÃ³dulo IV (GradCAM)